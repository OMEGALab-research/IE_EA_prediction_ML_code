{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = pd.read_pickle('outputs/source_descriptors_processed.pkl')\n",
    "target_df = pd.read_pickle('outputs/target_descriptors_calculated_n_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('outputs/non_constant_columns.pkl', 'rb') as f:\n",
    "    non_constant_columns = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_descriptors_df = source_df[non_constant_columns]\n",
    "target_descriptors_df = target_df[non_constant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_descriptors_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_descriptors_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del source_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source1_size = 233\n",
    "\n",
    "df1 = source_descriptors_df.iloc[:source1_size]\n",
    "df2 = source_descriptors_df.iloc[source1_size:]\n",
    "df3 = target_descriptors_df[target_df['Type'] == 'Online Dataset']\n",
    "df4 = target_descriptors_df[target_df['Type'] == 'Target Dataset']\n",
    "df5 = target_descriptors_df[target_df['Type'] == 'External Validation']\n",
    "\n",
    "combined_df = pd.concat([df1, df2, df3, df4, df5])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(combined_df)\n",
    "\n",
    "pca = PCA(n_components=2) # We want to reduce to 2 components\n",
    "principal_components = pca.fit_transform(scaled_data)\n",
    "\n",
    "pc_df1 = principal_components[:len(df1)]\n",
    "pc_df2 = principal_components[len(df1):len(df1) + len(df2)]\n",
    "pc_df3 = principal_components[len(df1)+len(df2):len(df1) + len(df2) + len(df3)]\n",
    "pc_df4 = principal_components[len(df1)+len(df2)+len(df3):len(df1) + len(df2) + len(df3)+len(df4)]\n",
    "pc_df5 = principal_components[len(df1)+len(df2)+len(df3)+len(df4):]\n",
    "df_save = {}\n",
    "for i in range(1, 6):\n",
    "    list_instance = []\n",
    "    if i == 3:\n",
    "        for j, row in target_df[target_df['Type']=='Online Dataset'].iterrows():\n",
    "            list_instance.append(row['Molecule'])\n",
    "    if i == 4:\n",
    "        for j, row in target_df[target_df['Type']=='Target Dataset'].iterrows():\n",
    "            list_instance.append(row['Molecule'])\n",
    "    if i == 5:\n",
    "        for j, row in target_df[target_df['Type']=='External Validation'].iterrows():\n",
    "            list_instance.append(row['Molecule'])\n",
    "    df_instance = pd.DataFrame(eval(f'pc_df{i}'), columns=[\"Principal Component 1\", \"Principal Component 2\"])\n",
    "    if len(df_instance) > 1000000:\n",
    "        df_instance = df_instance.sample(n=200000)\n",
    "    if i > 2:\n",
    "        df_instance[\"Molecule\"] = list_instance\n",
    "    df_instance.to_csv(f'outputs/EDA_source{i}.csv', sep= ';', index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(dpi=300)\n",
    "figure, axis = plt.subplots()\n",
    "axis.scatter(pc_df2[:, 0], pc_df2[:, 1], label=f'HCEP', alpha=0.5, edgecolors='none', zorder=0, color = '#8f0f06')\n",
    "axis.scatter(pc_df1[:, 0], pc_df1[:, 1], label=f'HOPV', alpha=0.7, edgecolors='none', zorder=1, color = '#06868f')\n",
    "# axis.scatter(pc_df3[:, 0], pc_df3[:, 1], color='k', label=f'Online n={len(df3)}', alpha=0.7, s=60, edgecolors='none', zorder=2, marker='*')\n",
    "axis.scatter(pc_df4[:, 0], pc_df4[:, 1], label=f'Target Dataset', alpha=0.7, edgecolors='none', zorder=3, marker='D', color = '#53068f')\n",
    "# axis.scatter(pc_df5[:, 0], pc_df5[:, 1], label=f'Validation n={len(df5)}', alpha=0.8, edgecolors='none', zorder=4, marker='x', color = '#418f06')\n",
    "axis.legend(loc='upper left', frameon= False)\n",
    "axis.text(axis.get_xlim()[0] - (axis.get_xlim()[1] - axis.get_xlim()[0])*0.11, axis.get_ylim()[1] - (axis.get_ylim()[1] - axis.get_ylim()[0])*(-0.02), 'a)', fontdict = {'size': 15})\n",
    "axis.set_xlabel('Principal Component 1', fontsize=18)\n",
    "axis.set_ylabel('Principal Component 2', fontsize=18)\n",
    "axis.minorticks_on()\n",
    "axis.tick_params('both', which = 'major', top = True, right = True, direction = 'in', width= 2, length= 4, labelsize=15)\n",
    "axis.tick_params('both', which = 'minor', top = True, right = True, direction = 'in', width= 1, length= 3)\n",
    "for spine in axis.spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "plt.savefig(\"EDA.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omega_lab_final_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
